\chapter{Conclusion}
\label{ch:conclusion}

Resilience consists of dependability and adaptivity and their sub characteristics. Dependability makes it possible to quantify the system resilience, by calculating the availability and evaluating the reliability of the system. The availability is calculated either as an aggregate or time-based availability, depending on the system and wish for quantification. Availability can be utilized as a quality measure, giving an indication of how well the system is performing. 
Adaptivity consist of four different measures, including capacity and redundancy. Capacity is the highest throughput of a system, while redundancy denote the excess capacity. Adaptivity correlates directly with the systems dependability. Improving either of the adaptivity measures have a positive impact on the system dependability. By improving capacity and redundancy of a given system, availability and therefore resilience is improved.

The microservice architecture was characterised and compared to two pre-existing architectural patterns. The microservice architecture explicitly forces developers to acknowledge the harsh nature of the production environment for distributed applications, emphasizing 'Design for Failure', considering system resilience and designing for it. By splitting the application into many small and isolated services, and deploying them in separate environments, the pitfalls of dependencies across integration points have been highlighted. This makes microservices extremely potent, when optimizing a system for resilience. Cloud Computing was defined to examine how it contributes to the possible designs and ways of deploying and managing distributed applications. Virtualization has been revolutionized by the development of containers, which has proven crucial for the microservice architectural pattern, and therefore for design of resilient system.

The direct correlation between dependability and adaptivity was shown through an experiment. Different languages, open source frameworks and tools were successfully utilized in the creation of test application and test tool. A cluster was created, making it possible to configure the capacity and redundancy as the test progressed. The availability of the test application was evaluated for different capacities, by looking at response times and success rate of the responses for each test. The experiment showed a clear correlation between the capacity of the application and the availability at different throughputs. As capacity was increased, so was the maximum throughput for the test application. The availability improvement was still less than expected not showing anything near a 1:1 relationship between increased capacity and attainable availability. These limitations were contributed to limitations in the load balancer of Kubernetes being incapable of distributing the load on all replicas at very high throughputs.



\section{Future Potentials}
As the knowledge sharing continues to grow, and so the available amount of open source projects. The potential for adopting the microservice architectural pattern will increase. As new bleeding edge technologies mature, the cost of adopting these technologies will drop. Certain open source projects will make get adopted by CNCF or similar foundations, improving documentation an possibly pushing towards a more unified cloud native landscape, reducing the current upkeep with understanding the full blown landscape.

Big enterprises similar to Danske Bank, will have to modernise many of their existing legacy systems, to improve resilience, which is the current motivating factor. At the same time traditional enterprises needs to modernize in order to keep up with the competition. Many of the early adopters of Cloud Computing and the microservice architecture have seen great benefits in creating small and autonomous teams, because the architecture supports it. This makes it possible to develop, release and continuously update systems more rapidly do to the decreased friction in the organisation. When enterprises similar to Danske Bank faces competition the three clear prohibitors for reaching quick and stable releases has to be removed. Meaning that new technology has to be utilized and existing process and organisational barriers have to be removed. Either modernize your organisation or loose out to the competition.

Danske Bank has not been able to utilize the public cloud because of consumer concerns and legislation. This has forced Danske Bank to create a hybrid cloud with other Danish enterprises in order to reap the benefits of Cloud Computing (especially the on-demand self-service and rapid elasticity). This has slowed down Cloud Computing adoption in many enterprises working with sensitive data if these barriers are removed, only organisation and process inhibitors are in the way for adopting microservices and drastically changing software development in enterprises such as Danske Bank. Microservices are not a silver bullet but have many important and new aspects, especially the underlying critique of the rigid structure of traditional enterprises is something very refreshing from a software engineering point of view.




